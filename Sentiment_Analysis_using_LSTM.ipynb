{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9fc8e08-87ad-4afa-867c-f85ea8c5e1f9",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Sentiment Analysis using LSTM</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad86fa3-c26a-4275-add2-7f693e84df4a",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5d5d969-9c74-4850-b45f-a772026481a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d07ec2-876a-4104-a1d7-ca82508a3cd9",
   "metadata": {},
   "source": [
    "### Load CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a31b5bfa-5714-4391-a4f6-46668376ada9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r\"E:\\Me\\coding\\IIT Guwahati Internship\\Codes\\archive\\IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c0b939d-b83e-4348-a99e-2b21356b38ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data) #converting to dataframe object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797dd5f4-a3e8-43ed-85de-1098ee69a9de",
   "metadata": {},
   "source": [
    "### Creating a simple tokeniser function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24c9690e-850f-4c75-b7b2-cda29fae684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_tokenize(text):\n",
    "    return re.findall(r\"\\b\\w+\\b\", text.lower())\n",
    "\n",
    "tokenized_texts = [simple_tokenize(text) for text in df['review']]\n",
    "all_words = [word for sent in tokenized_texts for word in sent]\n",
    "vocab = ['<PAD>', '<UNK>'] + [word for word, freq in Counter(all_words).items() if freq >= 1]\n",
    "word2idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "\n",
    "def encode_text(tokens, max_len=20):\n",
    "    ids = [word2idx.get(token, word2idx['<UNK>']) for token in tokens]\n",
    "    ids = ids[:max_len] + [word2idx['<PAD>']] * (max_len - len(ids))\n",
    "    return ids\n",
    "\n",
    "df['encoded'] = tokenized_texts\n",
    "df['encoded'] = df['encoded'].apply(lambda x: encode_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e5cb1f5-4dc8-4bd1-a330-43fc5f104a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_enc = LabelEncoder()\n",
    "df['label_id'] = label_enc.fit_transform(df['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62baec2-24c3-41fe-8128-08ab85fa624a",
   "metadata": {},
   "source": [
    "### Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9160f020-3ace-4ceb-bf63-df78a0f921ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(np.array(X), dtype=torch.long)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['encoded'], df['label_id'], test_size=0.2, random_state=42)\n",
    "train_dataset = TextDataset(list(X_train), list(y_train))\n",
    "test_dataset = TextDataset(list(X_test), list(y_test))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76b97ad9-515f-4fe4-93ad-db1749e2827d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        _, (hidden, _) = self.lstm(embedded)\n",
    "        return self.fc(hidden[-1])\n",
    "\n",
    "model = SentimentModel(vocab_size=len(vocab), embed_dim=50, hidden_dim=64, num_classes=len(label_enc.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c91678c0-7cd4-43f6-a8fd-73953088aa7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 12695.5052\n",
      "Epoch 2, Loss: 10351.1392\n",
      "Epoch 3, Loss: 8784.1330\n",
      "Epoch 4, Loss: 7199.8778\n",
      "Epoch 5, Loss: 5614.0160\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(5):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0143598e-f55c-422b-91fe-ec46dedb1247",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64bc6cb1-35b8-4420-91cc-4632ba25c5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 71.43%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        outputs = model(X_batch)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == y_batch).sum().item()\n",
    "        total += y_batch.size(0)\n",
    "\n",
    "print(f\"Test Accuracy: {correct/total * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97b24b3-f78a-424a-8674-239fa848911d",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553076e6-98e0-4ff1-a9c2-0eee1ea04f4d",
   "metadata": {},
   "source": [
    "1. https://github.com/bentrevett/pytorch-sentiment-analysis.git\n",
    "2. https://www.geeksforgeeks.org/deep-learning/how-to-use-pytorch-for-sentiment-analysis-on-textual-data/\n",
    "3. https://youtu.be/rsy5Ragmso8?feature=shared\n",
    "4. https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
